{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324766e2-9c1b-419b-abab-c79da63b2a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9068c973-549a-43c9-9a8c-e55a3183342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>downvotes</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pos_word1</th>\n",
       "      <th>pos_word2</th>\n",
       "      <th>pos_word3</th>\n",
       "      <th>neg_word1</th>\n",
       "      <th>neg_word2</th>\n",
       "      <th>neg_word3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1-more flexible2-bass is very high3-sound clar...</td>\n",
       "      <td>1390</td>\n",
       "      <td>276</td>\n",
       "      <td>good</td>\n",
       "      <td>awesome</td>\n",
       "      <td>good</td>\n",
       "      <td>support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Super sound and good looking I like that prize</td>\n",
       "      <td>643</td>\n",
       "      <td>133</td>\n",
       "      <td>good</td>\n",
       "      <td>super</td>\n",
       "      <td>prize</td>\n",
       "      <td>good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very much satisfied with the device at this pr...</td>\n",
       "      <td>1449</td>\n",
       "      <td>328</td>\n",
       "      <td>good</td>\n",
       "      <td>awesome</td>\n",
       "      <td>wonderful</td>\n",
       "      <td>wise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice headphone, bass was very good and sound i...</td>\n",
       "      <td>160</td>\n",
       "      <td>28</td>\n",
       "      <td>good</td>\n",
       "      <td>best</td>\n",
       "      <td>good</td>\n",
       "      <td>nice</td>\n",
       "      <td>complaint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Sound quality super battery backup super quali...</td>\n",
       "      <td>533</td>\n",
       "      <td>114</td>\n",
       "      <td>good</td>\n",
       "      <td>super</td>\n",
       "      <td>value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_id                                      product_title  \\\n",
       "0  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "1  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "2  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "3  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "4  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "\n",
       "   rating                                             review  upvotes  \\\n",
       "0       5  1-more flexible2-bass is very high3-sound clar...     1390   \n",
       "1       5     Super sound and good looking I like that prize      643   \n",
       "2       5  Very much satisfied with the device at this pr...     1449   \n",
       "3       5  Nice headphone, bass was very good and sound i...      160   \n",
       "4       5  Sound quality super battery backup super quali...      533   \n",
       "\n",
       "   downvotes sentiment pos_word1  pos_word2 pos_word3  neg_word1 neg_word2  \\\n",
       "0        276      good   awesome       good   support        NaN       NaN   \n",
       "1        133      good     super      prize      good        NaN       NaN   \n",
       "2        328      good   awesome  wonderful      wise        NaN       NaN   \n",
       "3         28      good      best       good      nice  complaint       NaN   \n",
       "4        114      good     super      value       NaN        NaN       NaN   \n",
       "\n",
       "  neg_word3  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'Avaliacao_Produtos_sentimento_EN.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0456fae-6ead-4153-aa2e-4880b97143cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "traducoes = {\n",
    "    'product_title': 'produto',\n",
    "    'rating':'avaliacao',\n",
    "    'sentiment': 'sentimento',\n",
    "    'pos_word1': 'palavra_positiva1',\n",
    "    'pos_word2': 'palavra_positiva2',\n",
    "    'pos_word3': 'palavra_positiva3',\n",
    "    'neg_word1': 'palavra_negativa1',\n",
    "    'neg_word2': 'palavra_negativa2',\n",
    "    'neg_word3': 'palavra_negativa3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5389b9dc-5d10-475b-9789-4dedae224db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>produto</th>\n",
       "      <th>avaliacao</th>\n",
       "      <th>review</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>downvotes</th>\n",
       "      <th>sentimento</th>\n",
       "      <th>palavra_positiva1</th>\n",
       "      <th>palavra_positiva2</th>\n",
       "      <th>palavra_positiva3</th>\n",
       "      <th>palavra_negativa1</th>\n",
       "      <th>palavra_negativa2</th>\n",
       "      <th>palavra_negativa3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1-more flexible2-bass is very high3-sound clar...</td>\n",
       "      <td>1390</td>\n",
       "      <td>276</td>\n",
       "      <td>good</td>\n",
       "      <td>awesome</td>\n",
       "      <td>good</td>\n",
       "      <td>support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Super sound and good looking I like that prize</td>\n",
       "      <td>643</td>\n",
       "      <td>133</td>\n",
       "      <td>good</td>\n",
       "      <td>super</td>\n",
       "      <td>prize</td>\n",
       "      <td>good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very much satisfied with the device at this pr...</td>\n",
       "      <td>1449</td>\n",
       "      <td>328</td>\n",
       "      <td>good</td>\n",
       "      <td>awesome</td>\n",
       "      <td>wonderful</td>\n",
       "      <td>wise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice headphone, bass was very good and sound i...</td>\n",
       "      <td>160</td>\n",
       "      <td>28</td>\n",
       "      <td>good</td>\n",
       "      <td>best</td>\n",
       "      <td>good</td>\n",
       "      <td>nice</td>\n",
       "      <td>complaint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Sound quality super battery backup super quali...</td>\n",
       "      <td>533</td>\n",
       "      <td>114</td>\n",
       "      <td>good</td>\n",
       "      <td>super</td>\n",
       "      <td>value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_id                                            produto  \\\n",
       "0  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "1  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "2  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "3  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "4  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "\n",
       "   avaliacao                                             review  upvotes  \\\n",
       "0          5  1-more flexible2-bass is very high3-sound clar...     1390   \n",
       "1          5     Super sound and good looking I like that prize      643   \n",
       "2          5  Very much satisfied with the device at this pr...     1449   \n",
       "3          5  Nice headphone, bass was very good and sound i...      160   \n",
       "4          5  Sound quality super battery backup super quali...      533   \n",
       "\n",
       "   downvotes sentimento palavra_positiva1 palavra_positiva2 palavra_positiva3  \\\n",
       "0        276       good           awesome              good           support   \n",
       "1        133       good             super             prize              good   \n",
       "2        328       good           awesome         wonderful              wise   \n",
       "3         28       good              best              good              nice   \n",
       "4        114       good             super             value               NaN   \n",
       "\n",
       "  palavra_negativa1 palavra_negativa2 palavra_negativa3  \n",
       "0               NaN               NaN               NaN  \n",
       "1               NaN               NaN               NaN  \n",
       "2               NaN               NaN               NaN  \n",
       "3         complaint               NaN               NaN  \n",
       "4               NaN               NaN               NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns=traducoes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8776df2-b131-48c1-9d4a-1ebde1d36739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.6 MB 6.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.6/11.6 MB 7.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 8.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 11.0 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "   ---------------------------------------- 0.0/564.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 564.3/564.3 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 16.2 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 18.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Installing collected packages: sentencepiece, safetensors, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ---------------- ----------------------- 2/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [tokenizers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   -------------------------------- ------- 4/5 [transformers]\n",
      "   ---------------------------------------- 5/5 [transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.35.3 safetensors-0.6.2 sentencepiece-0.2.1 tokenizers-0.22.1 transformers-4.56.2\n"
     ]
    }
   ],
   "source": [
    "pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed6c400-536d-41e3-ba4d-1217c1138c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.75.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\microsoft\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34c18c2-7b9a-441d-8881-3d1b9c27d0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Microsoft\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianTokenizer, TFMarianMTModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c66fb3b-4424-424d-88c8-59fe8726b4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Microsoft\\anaconda3\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784248d5b1e84cbaa6d529e0181328bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/313M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Microsoft\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Microsoft\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-ROMANCE. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Microsoft\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ROMANCE.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61d744786b04995993448b2258e1813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-en-ROMANCE\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = TFMarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f2d0233-54ce-4ff2-ab85-b30a73f1c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_texts(texts, batch_size=16):\n",
    "    results = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = [str(t) if t is not None else \"\" for t in texts[i:i+batch_size]]\n",
    "        encoded = tokenizer(batch, return_tensors=\"tf\", padding=True, truncation=True)  # << usa TensorFlow\n",
    "        translated = model.generate(**encoded)\n",
    "        results.extend([tokenizer.decode(t, skip_special_tokens=True) for t in translated])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71015a38-ec50-4cc8-86ae-ac823bec14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_translate = [\"sentimento\", \"palavra_positiva1\", \"palavra_positiva2\", \"palavra_positiva3\", \n",
    "                     \"palavra_negativa1\", \"palavra_negativa2\", \"palavra_negativa3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6d66f-22e1-4624-80a6-767c5040b6fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduzindo coluna: sentimento ...\n",
      "Traduzindo coluna: palavra_positiva1 ...\n"
     ]
    }
   ],
   "source": [
    "for col in cols_to_translate:\n",
    "    print(f\"Traduzindo coluna: {col} ...\")\n",
    "    df[col + \"_pt\"] = translate_texts(df[col].astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722056b-5b4d-4b4b-ac82-9e9133589bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
